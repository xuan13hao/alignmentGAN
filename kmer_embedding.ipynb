{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuan/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import fasta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWord_model(word,num_features,min_count, model, Unfile):\n",
    "\tword_model = \"\"\n",
    "\tif not os.path.isfile(model):\n",
    "\t\tsentence = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "\t\tnum_features = int(num_features)\n",
    "\t\tmin_word_count = int(min_count)\n",
    "\t\tnum_workers = 20\n",
    "\t\tcontext = 20\n",
    "\t\tdownsampling = 1e-3\n",
    "\n",
    "\t\tprint (\"Training Word2Vec model...\")\n",
    "\t\tword_model = Word2Vec(sentence, workers=num_workers,\\\n",
    "\t\t\t\t\t\tvector_size=num_features, min_count=min_word_count, \\\n",
    "\t\t\t\t\t\twindow=context, sample=downsampling, seed=1)\n",
    "\t\tword_model.init_sims(replace=False)\n",
    "\t\tword_model.save(model)\n",
    "\n",
    "\telse:\n",
    "\t\tprint (\"Loading Word2Vec model...\")\n",
    "\t\tword_model = Word2Vec.load(model)\n",
    "\n",
    "\treturn word_model\n",
    "\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "\tsentence = \"\"\n",
    "\tlength = len(dna)\n",
    "\n",
    "\tfor i in range(length - K + 1):\n",
    "\t\tsentence += dna[i: i + K] + \" \"\n",
    "\n",
    "\tsentence = sentence[0 : len(sentence) - 1]\n",
    "\treturn sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDNA_split(DNAdata,word):\n",
    "\tlist1 = []\n",
    "\tfor DNA in DNAdata:\n",
    "\t\tDNA = str(DNA).upper()\n",
    "\t\tlist1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\treturn list1\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,model,num_features):\n",
    "\tcounter = 0\n",
    "\tDNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\t\n",
    "\tfor DNA in DNAdata1:\n",
    "\t\tif counter % 1000 == 0:\n",
    "\t\t\tprint (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "\t\t\tsys.stdout.flush()\n",
    "\t\t# print(DNA)\n",
    "\t\tDNAFeatureVecs[counter][0:num_features] = np.mean(model.wv[DNA],axis = 0)\n",
    "\t\tcounter += 1\n",
    "\t# print()\n",
    "\treturn DNAFeatureVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "\tdataDataVecs = np.load(npyfile)\n",
    "\tg = open(svmfile,'w')\n",
    "\tprint(len(dataDataVecs))\n",
    "\t#print(dataDataVecs[0])\n",
    "\tm = 0\n",
    "\tfor i in range(len(dataDataVecs)):\n",
    "\t\tline = ''\n",
    "\t\tfor j in range(len(dataDataVecs[0])):\n",
    "\t\t\tif j == len(dataDataVecs[0])-1:\n",
    "\t\t\t\tline += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "\t\t\telse:\n",
    "\t\t\t\tline += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "\t\tm += 1\n",
    "\t\tif m < (pos_num+1):\n",
    "\t\t\tg.write('1\\t'+line)\n",
    "\t\telse:\n",
    "\t\t\tg.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "\tf = open(svmfile,'r')\n",
    "\tg = open(csvfile,'w')\n",
    "\tlines = f.readlines()\n",
    "\tlegth = len(lines[0].split('\t'))-1\n",
    "\t#print(legth)\n",
    "\tclassline = 'class'\n",
    "\tfor i in range(legth):\n",
    "\t\tclassline += ',%d'%(i+1)\n",
    "\tg.write(classline+'\\n')\n",
    "\n",
    "\tfor line in lines:\n",
    "\t\tline = line.strip('\\n').split('\t')\n",
    "\t\tg.write(line[0]+',')\n",
    "\n",
    "\t\tlegth2 = len(line[1:])\n",
    "\t\tm = 0\n",
    "\t\tfor j in line[1:]:\n",
    "\t\t\tif m == legth2-1:\n",
    "\t\t\t\tj = j.split(':')[-1]\n",
    "\t\t\t\tg.write(j)\n",
    "\t\t\t\tm += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tj = j.split(':')[-1]\n",
    "\t\t\t\tg.write(j+',')\n",
    "\t\t\t\tm += 1\n",
    "\t\tg.write('\\n')\n",
    "\n",
    "\tf.close()\n",
    "\tg.close()\n",
    "\n",
    "\n",
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.index_to_key:\n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(tokens))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model...\n",
      "tensor([[ 0.0176,  0.0667,  0.0221,  ..., -0.0744, -0.2162, -0.0947],\n",
      "        [-0.0174,  0.1039,  0.0093,  ..., -0.0561, -0.2392, -0.1010],\n",
      "        [-0.0323,  0.2350, -0.0935,  ...,  0.0359, -0.0663, -0.0698],\n",
      "        ...,\n",
      "        [-0.0328,  0.2764, -0.0981,  ...,  0.0402, -0.0752, -0.0719],\n",
      "        [-0.0414,  0.2943, -0.0995,  ...,  0.0307, -0.1264, -0.0769],\n",
      "        [-0.0479,  0.2816, -0.1071,  ...,  0.0428, -0.0820, -0.0520]])\n",
      "Embedding(64, 100)\n"
     ]
    }
   ],
   "source": [
    "kmer = 3\n",
    "pos_number = 10 # NOTE: the number of postive sample in test file\n",
    "seq_reads = []\n",
    "\n",
    "\n",
    "for record in fasta.parse('test.fa'):\n",
    "    seq_reads.append(str(record.seq))\n",
    "#### generate Unsupervised ##### \n",
    "Unfile = '%dUn'%(kmer)\n",
    "g = open(Unfile,'w')\n",
    "words1 = getDNA_split(seq_reads,kmer)\n",
    "\n",
    "for i in range(len(words1)):\n",
    "\tline = ' '.join(words1[i])\n",
    "\tg.write(line+'\\n')\n",
    "g.close()\n",
    "\n",
    "model = 'model_%d'%(kmer)\n",
    "fea_num = 100\n",
    "min_fea = 10\n",
    "wm = getWord_model(kmer,fea_num,min_fea,model,Unfile)\n",
    "word_model = Word2Vec.load(model)\n",
    "weights = torch.FloatTensor(word_model.wv.vectors)\n",
    "print(weights)\n",
    "embedding = nn.Embedding.from_pretrained(weights)\n",
    "print(embedding)\n",
    "\n",
    "query = 'ACG'\n",
    "query_id = torch.tensor(word_model.wv['ACG'])\n",
    "gensim_vector = torch.tensor(word_model.wv[query])\n",
    "# embedding_vector = embedding(query_id)\n",
    "# embedding_vector\n",
    "# gensim_vector\n",
    "# embedding_vector\n",
    "# print(gensim_vector==embedding_vector)\n",
    "# tsne_plot(wm)\n",
    "# dataDataVecs = getAvgFeatureVecs(words1,word_model,fea_num)\n",
    "# # print (dataDataVecs)\n",
    "# fea_npy = '%d_vecs.npy'%(kmer)\n",
    "# np.save(fea_npy,dataDataVecs)\n",
    "# words = list(wm.wv.key_to_index.keys())\n",
    "# for w in words:\n",
    "# \tprint(w)\n",
    "# print(wm.wv['ACG'])\n",
    "# vocab = wm.wv.key_to_index.keys()\n",
    "# for word in vocab:\n",
    "#     print(wm.wv.get_index(word))\n",
    "# X = model.wv[vocab]\n",
    "# #### npy To csv #####\n",
    "# fea_svm = '%d_vecs.svm'%(kmer)\n",
    "# fea_csv = '%d_vecs.csv'%(kmer)\n",
    "\n",
    "# npyTosvm(fea_npy, fea_svm,pos_number)\n",
    "# SVMtoCSV(fea_svm, fea_csv)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
