###### start to pretrain generator: 2023-02-08 15:42:31.753622
    training lstmCore: 2023-02-08 15:42:31.754824
###### start to pretrain generator: 2023-02-08 15:44:09.189457
    training lstmCore: 2023-02-08 15:44:09.190830
    training lstmCore: 2023-02-08 15:49:32.670034
    training lstmCore: 2023-02-08 15:51:20.631562
    training lstmCore: 2023-02-08 15:52:43.546752
    training lstmCore: 2023-02-08 15:52:57.784904
    training lstmCore: 2023-02-08 15:54:38.523077
    training lstmCore: 2023-02-08 15:58:47.948441
      epoch: 0 loss: 4.218552112579346
      epoch: 1 loss: 4.2168300946553545
      epoch: 2 loss: 4.2168277104695635
    training lstmCore: 2023-02-08 15:59:24.263633
      epoch: 0 loss: 4.220913569132487
      epoch: 1 loss: 4.21983528137207
      epoch: 2 loss: 4.22064733505249
    training lstmCore: 2023-02-08 16:06:11.146856
    training lstmCore: 2023-02-08 16:07:16.985955
    training lstmCore: 2023-02-08 16:08:05.791669
    training lstmCore: 2023-02-08 16:12:28.761510
    training lstmCore: 2023-02-08 16:13:44.196101
    training lstmCore: 2023-02-08 16:14:22.304465
    training lstmCore: 2023-02-08 16:14:49.974683
    training lstmCore: 2023-02-08 16:15:16.723389
    training lstmCore: 2023-02-08 16:15:41.089324
    training lstmCore: 2023-02-08 16:18:44.794826
    training lstmCore: 2023-02-08 16:22:45.921159
    training lstmCore: 2023-02-08 16:23:01.453687
    training lstmCore: 2023-02-08 16:23:13.570052
    training lstmCore: 2023-02-08 16:23:56.232494
    training lstmCore: 2023-02-08 16:25:12.087213
    training lstmCore: 2023-02-08 16:25:31.241555
    training lstmCore: 2023-02-08 16:26:04.293170
    training lstmCore: 2023-02-08 16:26:25.276456
    training lstmCore: 2023-02-08 16:26:53.867982
    training lstmCore: 2023-02-08 16:28:32.156726
    training lstmCore: 2023-02-08 16:29:47.605860
    training lstmCore: 2023-02-08 16:30:28.249367
      epoch: 0 loss: 4.195698579152425
      epoch: 1 loss: 4.194616317749023
      epoch: 2 loss: 4.195569038391113
    training lstmCore: 2023-02-08 16:35:20.575389
    training lstmCore: 2023-02-08 16:36:23.072234
      epoch: 0 loss: 4.215932687123616
      epoch: 1 loss: 4.2146023114522295
      epoch: 2 loss: 4.2167731920878095
    training lstmCore: 2023-02-08 16:38:35.294352
    training lstmCore: 2023-02-08 16:38:47.965478
    training lstmCore: 2023-02-08 16:39:20.100945
    training lstmCore: 2023-02-08 16:40:17.648613
    training lstmCore: 2023-02-08 16:40:41.881965
    training lstmCore: 2023-02-08 16:41:58.229366
    training lstmCore: 2023-02-08 16:42:24.048936
    training lstmCore: 2023-02-08 16:43:23.937793
    training discriminator: 2023-02-08 16:44:05.493432
      epoch: 0 loss: 0.6896582841873169
      epoch: 1 loss: 0.5370498299598694
      epoch: 2 loss: 0.45814281702041626
    training lstmCore: 2023-02-08 16:46:29.756761
    training lstmCore: 2023-02-08 16:47:07.377815
    training lstmCore: 2023-02-08 16:51:46.795001
    training lstmCore: 2023-02-08 16:53:30.584375
    training lstmCore: 2023-02-08 16:56:23.769250
    training lstmCore: 2023-02-08 17:06:33.196049
    training lstmCore: 2023-02-08 17:07:44.157970
    training lstmCore: 2023-02-08 17:11:43.154396
    training lstmCore: 2023-02-08 17:13:08.648327
    training lstmCore: 2023-02-08 17:15:12.392947
    training lstmCore: 2023-02-08 17:15:33.780437
    training lstmCore: 2023-02-08 17:16:03.650608
    training lstmCore: 2023-02-08 17:16:24.144414
      epoch: 0 loss: 4.214420477549235
      epoch: 1 loss: 4.213694095611572
      epoch: 2 loss: 4.212973753611247
    training lstmCore: 2023-02-08 17:16:49.596236
    training lstmCore: 2023-02-08 17:19:41.624109
    training lstmCore: 2023-02-08 17:20:08.745831
      epoch: 0 loss: 4.215702851613362
      epoch: 1 loss: 4.215414841969808
      epoch: 2 loss: 4.215751012166341
    training lstmCore: 2023-02-08 17:26:09.111698
    training lstmCore: 2023-02-08 17:26:30.285904
      epoch: 0 loss: 4.222841262817383
      epoch: 1 loss: 4.22177775700887
      epoch: 2 loss: 4.221291700998942
    training lstmCore: 2023-02-08 17:27:53.521733
    training lstmCore: 2023-02-08 17:43:21.827184
      epoch: 0 loss: 4.172077083587647
      epoch: 1 loss: 4.1661004543304445
      epoch: 2 loss: 4.160363864898682
    training lstmCore: 2023-02-08 17:45:02.959000
    training lstmCore: 2023-02-08 17:47:54.802065
      epoch: 0 loss: 4.214518404006958
      epoch: 1 loss: 4.212765455245972
      epoch: 2 loss: 4.211270189285278
    training lstmCore: 2023-02-08 17:48:26.592544
      epoch: 0 loss: 4.208787870407105
      epoch: 1 loss: 4.207252025604248
      epoch: 2 loss: 4.206105279922485
    training lstmCore: 2023-02-08 17:53:49.408180
      epoch: 0 loss: 4.2078453540802006
      epoch: 1 loss: 4.20674958229065
      epoch: 2 loss: 4.205109405517578
    training lstmCore: 2023-02-08 17:54:07.607656
      epoch: 0 loss: 4.194219779968262
      epoch: 1 loss: 4.193274974822998
      epoch: 2 loss: 4.191511392593384
    training lstmCore: 2023-02-08 18:01:35.369015
      epoch: 0 loss: 4.220563268661499
      epoch: 1 loss: 4.2195573329925535
      epoch: 2 loss: 4.218203544616699
