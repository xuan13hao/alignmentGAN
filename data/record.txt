###### start to pretrain generator: 2023-03-12 22:22:48.620990
    training lstmCore: 2023-03-12 22:22:51.222586
      epoch: 0 loss: 1.9002689838409423
      epoch: 1 loss: 1.8964126586914063
      epoch: 2 loss: 1.8912084102630615
      epoch: 3 loss: 1.8855632543563843
      epoch: 4 loss: 1.8795949220657349
      epoch: 5 loss: 1.875483250617981
      epoch: 6 loss: 1.8701653957366944
      epoch: 7 loss: 1.864263129234314
      epoch: 8 loss: 1.8594882488250732
      epoch: 9 loss: 1.8562315940856933
      epoch: 10 loss: 1.8511460065841674
      epoch: 11 loss: 1.8445063352584838
      epoch: 12 loss: 1.8409907579421998
      epoch: 13 loss: 1.8358166933059692
      epoch: 14 loss: 1.8309959650039673
      epoch: 15 loss: 1.8269217014312744
      epoch: 16 loss: 1.8204560041427613
      epoch: 17 loss: 1.8165659189224244
      epoch: 18 loss: 1.8117499351501465
      epoch: 19 loss: 1.8078473091125489
      epoch: 20 loss: 1.80219566822052
      epoch: 21 loss: 1.7978978157043457
      epoch: 22 loss: 1.7933045864105224
      epoch: 23 loss: 1.789993977546692
      epoch: 24 loss: 1.7862711429595948
      epoch: 25 loss: 1.7793724060058593
      epoch: 26 loss: 1.776050329208374
      epoch: 27 loss: 1.7696896314620971
      epoch: 28 loss: 1.767002010345459
      epoch: 29 loss: 1.7638817310333252
      epoch: 30 loss: 1.7585489749908447
      epoch: 31 loss: 1.754480743408203
      epoch: 32 loss: 1.7499355792999267
      epoch: 33 loss: 1.746697187423706
      epoch: 34 loss: 1.7411643266677856
      epoch: 35 loss: 1.7378025293350219
      epoch: 36 loss: 1.7339046716690063
      epoch: 37 loss: 1.7301076650619507
      epoch: 38 loss: 1.7246307134628296
      epoch: 39 loss: 1.7216322898864747
      epoch: 40 loss: 1.7166485786437988
      epoch: 41 loss: 1.7132266998291015
      epoch: 42 loss: 1.7101529836654663
      epoch: 43 loss: 1.7065805673599244
      epoch: 44 loss: 1.7013939142227172
      epoch: 45 loss: 1.6989468812942505
      epoch: 46 loss: 1.6959540128707886
      epoch: 47 loss: 1.6908188104629516
      epoch: 48 loss: 1.687061357498169
      epoch: 49 loss: 1.684067726135254
      epoch: 50 loss: 1.680507206916809
      epoch: 51 loss: 1.6766121149063111
      epoch: 52 loss: 1.6733672618865967
      epoch: 53 loss: 1.6690157175064086
      epoch: 54 loss: 1.6656400442123414
      epoch: 55 loss: 1.6624346256256104
      epoch: 56 loss: 1.6595142602920532
      epoch: 57 loss: 1.6547111034393311
      epoch: 58 loss: 1.6529802083969116
      epoch: 59 loss: 1.6489096403121948
      epoch: 60 loss: 1.6455816745758056
      epoch: 61 loss: 1.6419201135635375
      epoch: 62 loss: 1.638855528831482
      epoch: 63 loss: 1.63695547580719
      epoch: 64 loss: 1.6333646774291992
      epoch: 65 loss: 1.6296543836593629
      epoch: 66 loss: 1.6258294343948365
      epoch: 67 loss: 1.6233729124069214
      epoch: 68 loss: 1.6201838254928589
      epoch: 69 loss: 1.6156975507736206
      epoch: 70 loss: 1.6145573139190674
      epoch: 71 loss: 1.6115585088729858
      epoch: 72 loss: 1.6069624185562135
      epoch: 73 loss: 1.606178069114685
      epoch: 74 loss: 1.6022065162658692
      epoch: 75 loss: 1.5985224008560182
      epoch: 76 loss: 1.5976800203323365
      epoch: 77 loss: 1.5929994106292724
      epoch: 78 loss: 1.5910511016845703
      epoch: 79 loss: 1.5884989500045776
      epoch: 80 loss: 1.5856575965881348
      epoch: 81 loss: 1.583071756362915
      epoch: 82 loss: 1.580396580696106
      epoch: 83 loss: 1.5786357402801514
      epoch: 84 loss: 1.575001311302185
      epoch: 85 loss: 1.5727657318115233
      epoch: 86 loss: 1.5709208726882935
      epoch: 87 loss: 1.5683048009872436
      epoch: 88 loss: 1.5652852535247803
      epoch: 89 loss: 1.5637189865112304
      epoch: 90 loss: 1.5605963468551636
      epoch: 91 loss: 1.5586177349090575
      epoch: 92 loss: 1.556474208831787
      epoch: 93 loss: 1.5544550657272338
      epoch: 94 loss: 1.551168394088745
      epoch: 95 loss: 1.5503267288208007
      epoch: 96 loss: 1.5485633134841919
      epoch: 97 loss: 1.5459064483642577
      epoch: 98 loss: 1.5440603733062743
      epoch: 99 loss: 1.5401619911193847
      epoch: 100 loss: 1.5392744541168213
      epoch: 101 loss: 1.5358347177505494
      epoch: 102 loss: 1.534350538253784
      epoch: 103 loss: 1.5335253953933716
      epoch: 104 loss: 1.5317458629608154
      epoch: 105 loss: 1.528359627723694
      epoch: 106 loss: 1.5262718200683594
      epoch: 107 loss: 1.5251063585281373
      epoch: 108 loss: 1.5234402179718018
      epoch: 109 loss: 1.5211845636367798
      epoch: 110 loss: 1.519343614578247
      epoch: 111 loss: 1.517755937576294
      epoch: 112 loss: 1.5150290250778198
      epoch: 113 loss: 1.5140883922576904
      epoch: 114 loss: 1.5102906465530395
      epoch: 115 loss: 1.5105251789093017
      epoch: 116 loss: 1.507065725326538
      epoch: 117 loss: 1.5083742141723633
      epoch: 118 loss: 1.504609727859497
      epoch: 119 loss: 1.504466700553894
###### start to pretrain discriminator: 2023-03-12 22:22:57.920474
###### start to pretrain generator: 2023-03-12 22:23:22.267548
    training lstmCore: 2023-03-12 22:23:24.547381
      epoch: 0 loss: 1.870487904548645
      epoch: 1 loss: 1.8678293466567992
      epoch: 2 loss: 1.8614184856414795
      epoch: 3 loss: 1.8565831899642944
      epoch: 4 loss: 1.8532212972640991
      epoch: 5 loss: 1.846059465408325
      epoch: 6 loss: 1.8426772832870484
      epoch: 7 loss: 1.8378474950790404
      epoch: 8 loss: 1.8334428071975708
      epoch: 9 loss: 1.828565812110901
      epoch: 10 loss: 1.824626660346985
      epoch: 11 loss: 1.819969654083252
      epoch: 12 loss: 1.8168019771575927
      epoch: 13 loss: 1.812015962600708
      epoch: 14 loss: 1.8072031259536743
      epoch: 15 loss: 1.8036840200424193
      epoch: 16 loss: 1.7982216835021974
      epoch: 17 loss: 1.7937734127044678
      epoch: 18 loss: 1.7899261236190795
      epoch: 19 loss: 1.7854195833206177
      epoch: 20 loss: 1.781822180747986
      epoch: 21 loss: 1.7780884981155396
      epoch: 22 loss: 1.7732191562652588
      epoch: 23 loss: 1.7696251392364502
      epoch: 24 loss: 1.765445590019226
      epoch: 25 loss: 1.7611168384552003
      epoch: 26 loss: 1.7559199333190918
      epoch: 27 loss: 1.7535099267959595
      epoch: 28 loss: 1.7485437393188477
      epoch: 29 loss: 1.7444381237030029
      epoch: 30 loss: 1.7421819686889648
      epoch: 31 loss: 1.7373082876205443
      epoch: 32 loss: 1.7336202383041381
      epoch: 33 loss: 1.7304595708847046
      epoch: 34 loss: 1.7263663291931153
      epoch: 35 loss: 1.7226823806762694
      epoch: 36 loss: 1.7178146362304687
      epoch: 37 loss: 1.7162945747375489
      epoch: 38 loss: 1.7124456644058228
      epoch: 39 loss: 1.7094329118728637
      epoch: 40 loss: 1.704989981651306
      epoch: 41 loss: 1.70244619846344
      epoch: 42 loss: 1.698256492614746
      epoch: 43 loss: 1.6942068576812743
      epoch: 44 loss: 1.6902228355407716
      epoch: 45 loss: 1.6870133876800537
      epoch: 46 loss: 1.6834692239761353
      epoch: 47 loss: 1.6797595739364624
      epoch: 48 loss: 1.6767354011535645
      epoch: 49 loss: 1.6735683917999267
      epoch: 50 loss: 1.6695907354354858
      epoch: 51 loss: 1.6659006834030152
      epoch: 52 loss: 1.6657828569412232
      epoch: 53 loss: 1.6604244232177734
      epoch: 54 loss: 1.6584520101547242
      epoch: 55 loss: 1.6543699264526368
      epoch: 56 loss: 1.6524591207504273
      epoch: 57 loss: 1.648818850517273
      epoch: 58 loss: 1.646073341369629
      epoch: 59 loss: 1.6427997589111327
      epoch: 60 loss: 1.638255786895752
      epoch: 61 loss: 1.6350311994552613
      epoch: 62 loss: 1.6330482959747314
      epoch: 63 loss: 1.6309782981872558
      epoch: 64 loss: 1.6288042068481445
      epoch: 65 loss: 1.6235992908477783
      epoch: 66 loss: 1.6228557586669923
      epoch: 67 loss: 1.6185499906539917
      epoch: 68 loss: 1.617200779914856
      epoch: 69 loss: 1.613875961303711
      epoch: 70 loss: 1.6107075929641723
      epoch: 71 loss: 1.607050371170044
      epoch: 72 loss: 1.6046563625335692
      epoch: 73 loss: 1.6027616739273072
      epoch: 74 loss: 1.6006617069244384
      epoch: 75 loss: 1.5985485076904298
      epoch: 76 loss: 1.5944780111312866
      epoch: 77 loss: 1.5926332950592041
      epoch: 78 loss: 1.5900874376296996
      epoch: 79 loss: 1.5878626585006714
      epoch: 80 loss: 1.5856765270233155
      epoch: 81 loss: 1.5829463720321655
      epoch: 82 loss: 1.5821252346038819
      epoch: 83 loss: 1.578245496749878
      epoch: 84 loss: 1.5758965730667114
      epoch: 85 loss: 1.5736999273300172
      epoch: 86 loss: 1.5713564157485962
      epoch: 87 loss: 1.5686888933181762
      epoch: 88 loss: 1.5678508281707764
      epoch: 89 loss: 1.5641278266906737
      epoch: 90 loss: 1.5630834817886352
      epoch: 91 loss: 1.559898281097412
      epoch: 92 loss: 1.558742928504944
      epoch: 93 loss: 1.5562401294708252
      epoch: 94 loss: 1.5547519207000733
      epoch: 95 loss: 1.551662063598633
      epoch: 96 loss: 1.5495522975921632
      epoch: 97 loss: 1.5490443229675293
      epoch: 98 loss: 1.54589102268219
      epoch: 99 loss: 1.5441707372665405
      epoch: 100 loss: 1.5435253381729126
      epoch: 101 loss: 1.5406922340393066
      epoch: 102 loss: 1.539526605606079
      epoch: 103 loss: 1.5371963024139403
      epoch: 104 loss: 1.5329744338989257
      epoch: 105 loss: 1.532132363319397
      epoch: 106 loss: 1.5313477039337158
      epoch: 107 loss: 1.5292961597442627
      epoch: 108 loss: 1.5265109300613404
      epoch: 109 loss: 1.5251667261123658
      epoch: 110 loss: 1.5239530086517334
      epoch: 111 loss: 1.5232224464416504
      epoch: 112 loss: 1.5216047763824463
      epoch: 113 loss: 1.5191444396972655
      epoch: 114 loss: 1.5178393602371216
      epoch: 115 loss: 1.5157231569290162
      epoch: 116 loss: 1.5124793291091918
      epoch: 117 loss: 1.5127243518829345
      epoch: 118 loss: 1.5092813968658447
      epoch: 119 loss: 1.5095746278762818
###### start to pretrain discriminator: 2023-03-12 22:23:31.128433
    training discriminator: 2023-03-12 22:23:31.295630
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
###### start to train adversarial net: 2023-03-12 22:23:36.221922
batch: 0 : 2023-03-12 22:23:36.221999
    training generator: 2023-03-12 22:25:33.509338
      epoch: 0 loss: -88.26065826416016
  iter_n_dis: 0 : 2023-03-12 22:25:33.551483
    training discriminator: 2023-03-12 22:25:33.858658
      epoch: 0 loss: 0.7750277876853943
      epoch: 1 loss: 0.7346503049135208
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:25:37.559332
    training discriminator: 2023-03-12 22:25:37.803777
      epoch: 0 loss: 0.7856851607561112
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:25:41.220158
    training discriminator: 2023-03-12 22:25:41.440742
      epoch: 0 loss: 0.7640345007181167
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 1 : 2023-03-12 22:25:44.932712
    training generator: 2023-03-12 22:27:41.186973
      epoch: 0 loss: -87.78421020507812
  iter_n_dis: 0 : 2023-03-12 22:27:41.197754
    training discriminator: 2023-03-12 22:27:41.479416
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:27:45.033294
    training discriminator: 2023-03-12 22:27:45.307636
      epoch: 0 loss: 0.7927709341049194
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:27:48.842193
    training discriminator: 2023-03-12 22:27:49.077198
      epoch: 0 loss: 0.772728556394577
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 2 : 2023-03-12 22:27:52.578454
    training generator: 2023-03-12 22:29:51.445594
      epoch: 0 loss: -87.92686462402344
  iter_n_dis: 0 : 2023-03-12 22:29:51.468037
    training discriminator: 2023-03-12 22:29:51.715654
      epoch: 0 loss: 0.7767217069864273
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:29:55.269889
    training discriminator: 2023-03-12 22:29:55.484644
      epoch: 0 loss: 0.7876167953014374
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:29:59.342237
    training discriminator: 2023-03-12 22:29:59.613274
      epoch: 0 loss: 0.7023299098014831
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 3 : 2023-03-12 22:30:03.221875
    training generator: 2023-03-12 22:31:59.132491
      epoch: 0 loss: -90.69110107421875
  iter_n_dis: 0 : 2023-03-12 22:31:59.143810
    training discriminator: 2023-03-12 22:31:59.368211
      epoch: 0 loss: 0.6510028749704361
      epoch: 1 loss: 0.807074710726738
      epoch: 2 loss: 0.9045814990997314
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:32:02.915901
    training discriminator: 2023-03-12 22:32:03.194919
      epoch: 0 loss: 0.693216609954834
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:32:06.881239
    training discriminator: 2023-03-12 22:32:07.087437
      epoch: 0 loss: 0.8352996528148651
      epoch: 1 loss: 0.7476050317287445
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 4 : 2023-03-12 22:32:10.615691
###### start to pretrain generator: 2023-03-12 22:33:00.373154
    training lstmCore: 2023-03-12 22:33:02.766574
      epoch: 0 loss: 1.9194116830825805
      epoch: 1 loss: 1.914403748512268
      epoch: 2 loss: 1.9096508979797364
      epoch: 3 loss: 1.903287982940674
      epoch: 4 loss: 1.8979280471801758
      epoch: 5 loss: 1.892460036277771
      epoch: 6 loss: 1.8868458986282348
      epoch: 7 loss: 1.8811177730560302
      epoch: 8 loss: 1.8769929885864258
      epoch: 9 loss: 1.8705052852630615
      epoch: 10 loss: 1.8644525051116942
      epoch: 11 loss: 1.8613350629806518
      epoch: 12 loss: 1.856842565536499
      epoch: 13 loss: 1.850585675239563
      epoch: 14 loss: 1.8473256826400757
      epoch: 15 loss: 1.841292643547058
      epoch: 16 loss: 1.8378520011901855
      epoch: 17 loss: 1.8320386171340943
      epoch: 18 loss: 1.827769684791565
      epoch: 19 loss: 1.8235441446304321
      epoch: 20 loss: 1.8185713052749635
      epoch: 21 loss: 1.8127683639526366
      epoch: 22 loss: 1.8096064329147339
      epoch: 23 loss: 1.8060275316238403
      epoch: 24 loss: 1.7998847723007203
      epoch: 25 loss: 1.7975210189819335
      epoch: 26 loss: 1.7891889333724975
      epoch: 27 loss: 1.7864868879318236
      epoch: 28 loss: 1.7816941738128662
      epoch: 29 loss: 1.7755556106567383
      epoch: 30 loss: 1.7738442182540894
      epoch: 31 loss: 1.768916130065918
      epoch: 32 loss: 1.7633110284805298
      epoch: 33 loss: 1.7599961757659912
      epoch: 34 loss: 1.7556966304779054
      epoch: 35 loss: 1.7506511926651
      epoch: 36 loss: 1.7479593276977539
      epoch: 37 loss: 1.74291033744812
      epoch: 38 loss: 1.7380429983139039
      epoch: 39 loss: 1.735442614555359
      epoch: 40 loss: 1.7306548357009888
      epoch: 41 loss: 1.7268934965133667
      epoch: 42 loss: 1.7228965044021607
      epoch: 43 loss: 1.7194542169570923
      epoch: 44 loss: 1.7150709629058838
      epoch: 45 loss: 1.711838459968567
      epoch: 46 loss: 1.706870150566101
      epoch: 47 loss: 1.7043759107589722
      epoch: 48 loss: 1.7013178825378419
      epoch: 49 loss: 1.696994161605835
      epoch: 50 loss: 1.6914878606796264
      epoch: 51 loss: 1.6885391235351563
      epoch: 52 loss: 1.686141562461853
      epoch: 53 loss: 1.680800461769104
      epoch: 54 loss: 1.6780337810516357
      epoch: 55 loss: 1.6735882997512816
      epoch: 56 loss: 1.671003484725952
      epoch: 57 loss: 1.6679494619369506
      epoch: 58 loss: 1.6633445739746093
      epoch: 59 loss: 1.6608044862747193
      epoch: 60 loss: 1.6575426816940309
      epoch: 61 loss: 1.6547189235687256
      epoch: 62 loss: 1.6501434803009034
      epoch: 63 loss: 1.6490569114685059
      epoch: 64 loss: 1.6442903280258179
      epoch: 65 loss: 1.641614556312561
      epoch: 66 loss: 1.639494776725769
      epoch: 67 loss: 1.6350988149642944
      epoch: 68 loss: 1.6318840980529785
      epoch: 69 loss: 1.6289045572280885
      epoch: 70 loss: 1.6259092092514038
      epoch: 71 loss: 1.6222859621047974
      epoch: 72 loss: 1.6197230815887451
      epoch: 73 loss: 1.6168145418167115
      epoch: 74 loss: 1.614085578918457
      epoch: 75 loss: 1.611896848678589
      epoch: 76 loss: 1.6087877035140992
      epoch: 77 loss: 1.6037888050079345
      epoch: 78 loss: 1.603040099143982
      epoch: 79 loss: 1.600474214553833
      epoch: 80 loss: 1.5975847244262695
      epoch: 81 loss: 1.5941442728042603
      epoch: 82 loss: 1.5905885457992555
      epoch: 83 loss: 1.5894307136535644
      epoch: 84 loss: 1.5861233472824097
      epoch: 85 loss: 1.5843567609786988
      epoch: 86 loss: 1.5812732696533203
      epoch: 87 loss: 1.5791261911392211
      epoch: 88 loss: 1.57436261177063
      epoch: 89 loss: 1.5736745119094848
      epoch: 90 loss: 1.5702177047729493
      epoch: 91 loss: 1.5700914144515992
      epoch: 92 loss: 1.5668045997619628
      epoch: 93 loss: 1.5633490324020385
      epoch: 94 loss: 1.5636396408081055
      epoch: 95 loss: 1.5595422029495238
      epoch: 96 loss: 1.5571364641189576
      epoch: 97 loss: 1.5554102420806886
      epoch: 98 loss: 1.5533956050872804
      epoch: 99 loss: 1.55119788646698
      epoch: 100 loss: 1.5492393493652343
      epoch: 101 loss: 1.545981478691101
      epoch: 102 loss: 1.545195722579956
      epoch: 103 loss: 1.5413626909255982
      epoch: 104 loss: 1.5415245056152345
      epoch: 105 loss: 1.5385512590408326
      epoch: 106 loss: 1.5364526987075806
      epoch: 107 loss: 1.5337144374847411
      epoch: 108 loss: 1.5318089962005614
      epoch: 109 loss: 1.531508779525757
      epoch: 110 loss: 1.5301541090011597
      epoch: 111 loss: 1.5271158695220948
      epoch: 112 loss: 1.5263285398483277
      epoch: 113 loss: 1.526420283317566
      epoch: 114 loss: 1.5217613697052002
      epoch: 115 loss: 1.5211302280426025
      epoch: 116 loss: 1.5193591117858887
      epoch: 117 loss: 1.5164869546890258
      epoch: 118 loss: 1.5153878927230835
      epoch: 119 loss: 1.512940812110901
###### start to pretrain discriminator: 2023-03-12 22:33:09.804208
    training discriminator: 2023-03-12 22:33:09.966310
      epoch: 0 loss: 0.7775444775819779
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
###### start to train adversarial net: 2023-03-12 22:33:15.505460
batch: 0 : 2023-03-12 22:33:15.505555
    training generator: 2023-03-12 22:35:17.295358
      epoch: 0 loss: -91.95951080322266
  iter_n_dis: 0 : 2023-03-12 22:35:17.307174
    training discriminator: 2023-03-12 22:35:17.567533
      epoch: 0 loss: 0.7965279400348664
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:35:21.155889
    training discriminator: 2023-03-12 22:35:21.373008
      epoch: 0 loss: 0.7964944869279862
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:35:24.822239
    training discriminator: 2023-03-12 22:35:25.109446
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 1 : 2023-03-12 22:35:28.827707
    training generator: 2023-03-12 22:37:29.989256
      epoch: 0 loss: -92.69389343261719
  iter_n_dis: 0 : 2023-03-12 22:37:30.016802
    training discriminator: 2023-03-12 22:37:30.273665
      epoch: 0 loss: 0.6987083911895752
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:37:34.163443
    training discriminator: 2023-03-12 22:37:34.380241
      epoch: 0 loss: 0.8037802785634994
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:37:37.736650
    training discriminator: 2023-03-12 22:37:37.996831
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 2 : 2023-03-12 22:37:41.287883
    training generator: 2023-03-12 22:39:43.874396
      epoch: 0 loss: -95.11552429199219
  iter_n_dis: 0 : 2023-03-12 22:39:43.885042
    training discriminator: 2023-03-12 22:39:44.190021
      epoch: 0 loss: 0.7948711425065994
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:39:47.316859
    training discriminator: 2023-03-12 22:39:47.553218
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:39:50.932607
    training discriminator: 2023-03-12 22:39:51.138783
      epoch: 0 loss: 0.8167686462402344
      epoch: 1 loss: 0.7440458446741104
      epoch: 2 loss: 0.7047258108854294
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 3 : 2023-03-12 22:39:54.326775
    training generator: 2023-03-12 22:41:58.893217
      epoch: 0 loss: -93.0305404663086
  iter_n_dis: 0 : 2023-03-12 22:41:58.903080
    training discriminator: 2023-03-12 22:41:59.127578
      epoch: 0 loss: 0.7777694433927536
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:42:02.786710
    training discriminator: 2023-03-12 22:42:03.037068
      epoch: 0 loss: 0.7355932265520095
      epoch: 1 loss: 0.8107102930545806
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:42:06.877156
    training discriminator: 2023-03-12 22:42:07.146294
      epoch: 0 loss: 0.7944551914930343
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 4 : 2023-03-12 22:42:11.198048
    training generator: 2023-03-12 22:44:16.305866
      epoch: 0 loss: -91.88809967041016
  iter_n_dis: 0 : 2023-03-12 22:44:16.316573
    training discriminator: 2023-03-12 22:44:16.523150
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 1 : 2023-03-12 22:44:19.767869
    training discriminator: 2023-03-12 22:44:20.020684
      epoch: 0 loss: 0.6931471824645996
      epoch: 1 loss: 0.6931471824645996
      epoch: 2 loss: 0.6931471824645996
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
  iter_n_dis: 2 : 2023-03-12 22:44:23.217793
    training discriminator: 2023-03-12 22:44:23.448885
      epoch: 0 loss: 0.5515392690896987
      epoch: 1 loss: 0.7543511271476746
      epoch: 2 loss: 0.8508674621582031
      epoch: 3 loss: 0.6931471824645996
      epoch: 4 loss: 0.6931471824645996
batch: 5 : 2023-03-12 22:44:26.615745
